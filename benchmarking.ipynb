{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "from statsmodels.tsa.api import ExponentialSmoothing, SimpleExpSmoothing, Holt\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import os, warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecasting and benchmarking\n",
    "def benchmarking(df, var_name, result_file, no_exper = 10):\n",
    "    end_index_of_df = len(df)\n",
    "    \n",
    "    lead_times = [1, 3, 6 , 12, 18, 24]\n",
    "    previous_time = 24000\n",
    "    \n",
    "    no_of_experiments = no_exper\n",
    "\n",
    "    text_file = open(result_file, \"w\")\n",
    "    text_file.write(\"time, our, naive, average \\n\")\n",
    "\n",
    "    for lead_time in lead_times:\n",
    "        print('computing for lead time = ', str(lead_time), ' hours with history of ', str(previous_time), ' hours')\n",
    "        \n",
    "        rmse_array = []\n",
    "        persist_array = []\n",
    "        average_array = []\n",
    "\n",
    "        for _ in range(no_of_experiments):\n",
    "            offset = previous_time + lead_time\n",
    "            start_index = random.randint(0, end_index_of_df - offset)\n",
    "            #print(start_index)\n",
    "            train = df[start_index:start_index+previous_time]\n",
    "            test = df[start_index+previous_time:start_index+offset]\n",
    "\n",
    "            y_hat_avg = test.copy()\n",
    "            print('computation started')\n",
    "          \n",
    "            fit1 = ExponentialSmoothing(np.asarray(train[var_name]), seasonal_periods=240, trend='add', seasonal='add', ).fit()\n",
    "            y_hat_avg['predicted'] = fit1.forecast(len(test))\n",
    "\n",
    "            # persistence\n",
    "            last_value = train[var_name].iloc[-1]\n",
    "            y_hat_avg['naive'] = last_value * np.ones(len(test))\n",
    "\n",
    "            # average\n",
    "            mean_training_value = np.mean(train[var_name])\n",
    "            y_hat_avg['aver'] = mean_training_value * np.ones(len(test))\n",
    "\n",
    "            print('computation completed')\n",
    "\n",
    "            # computing the error for exponential smoothing\n",
    "            a = y_hat_avg[var_name]\n",
    "            b = y_hat_avg['predicted']\n",
    "            rmse_value = np.sqrt(np.mean((b - a) ** 2))\n",
    "            rmse_array.append(rmse_value)\n",
    "\n",
    "            # computing the error for persistence model\n",
    "            a = y_hat_avg[var_name]\n",
    "            b = y_hat_avg['naive']\n",
    "            rmse_value = np.sqrt(np.mean((b - a) ** 2))\n",
    "            persist_array.append(rmse_value)\n",
    "\n",
    "            # computing the error for average model\n",
    "            a = y_hat_avg[var_name]\n",
    "            b = y_hat_avg['aver']\n",
    "            rmse_value = np.sqrt(np.mean((b - a) ** 2))\n",
    "            average_array.append(rmse_value)\n",
    "\n",
    "        rmse_array = np.array(rmse_array)\n",
    "        persist_array = np.array(persist_array)\n",
    "        average_array = np.array(average_array)\n",
    "\n",
    "        text_file.write(\"%s, %s, %s, %s \\n\" % (lead_time, np.mean(rmse_array), np.mean(persist_array), np.mean(average_array)))\n",
    "\n",
    "    text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "file = r'./data/mean_T_hourly.csv'\n",
    "df = pd.read_csv(file, index_col='time').drop(['level'], axis=1)\n",
    "\n",
    "#result save to comparison_50runs.txt file\n",
    "res_file = r'./results/comparison_50runs.txt'\n",
    "\n",
    "# call benchmarking function\n",
    "benchmarking(df, 'Temperature', res_file, 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
